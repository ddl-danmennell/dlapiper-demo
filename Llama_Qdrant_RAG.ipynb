{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed201bf",
   "metadata": {},
   "source": [
    "# Document Search using Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In this project we demonstrate the use of a pre-trained Large Language Model (LLM) in Domino and the process of augmenting this model using Retrieval Augmented Generation (RAG) with documents to tailor to our use case. We will use the Meta's open source [Llama2 model](https://ai.meta.com/llama/), the [Qdrant vector database](https://qdrant.tech/) and the [LangChain framework](https://www.langchain.com/) to enable us to run the entire chain on Domino.\n",
    "\n",
    "In this notebook we will:\n",
    "1. Fetch and Process the Documents\n",
    "2. Initialise the Vector Store\n",
    "3. Fetch and Initialise the Llama2 Model\n",
    "4. Create the QA chain and test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76cf8b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import all the dependencies\n",
    "from qdrant_client import models, QdrantClient\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.vectorstores.qdrant import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from peft import PeftModel, PeftConfig\n",
    "#\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90800f",
   "metadata": {},
   "source": [
    "## Get Our Documents And Embeddings\n",
    "In this example we will read from a document in our repository in the sample_data folder.\n",
    "\n",
    "**Note: You will need to customise this section to your specific use case**\n",
    "\n",
    "Domino has many ways to access data. Please see our [documentation to find the method that suits your use case](https://docs.dominodatalab.com/en/latest/user_guide/16d9c1/work-with-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160eb12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the document that you need to parse, please change the location to where the pdf resides\n",
    "\n",
    "# Load 1 PDF file\n",
    "# loader = PyPDFLoader(\"/mnt/code/sample_data/MLOps_whitepaper.pdf\")\n",
    "# or load an entire folder\n",
    "loader = PyPDFDirectoryLoader(\"/mnt/code/data/dla\")\n",
    "data = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e008c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 269 chunks in the documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(data)} chunks in the documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb61618c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='the charge points and any associated substation \\nrelocation/connection issues. \\n• Non-compete/right of first refusal – given the \\ncommercial investment by EV charge point \\nproviders in new sites, they are keen to ensure \\ntheir initial investment is not passed onto their \\ncompetitors. The EV charge point providers \\ntherefore seek to include limitations on the \\nlandlord’s ability to grant interests to other EV \\ncharge point providers completely or require \\nthe landlord to offer the original EV charge \\npoint provider the right to tender for additional \\ninstallation opportunities first. \\n• Rental models – EV charge point leases include \\na range of different revenue sharing options \\nbetween landlords and the charge point providers. \\nThese include a revenue share being paid to the \\nlandlord based on the amount of electricity used by \\nthe charge point in a monthly period, a per parking \\nbay or charge point fee or a profit rent based on \\nthe profits made by the charge point provider after' metadata={'source': '/mnt/code/data/dla/A22945_Energy_Handbook_for_Landlords_Booklet_V4 25042024.pdf', 'page': 10}\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample page\n",
    "print(data[random.randint(0, len(data)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01f94be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 269\n"
     ]
    }
   ],
   "source": [
    "# Split the data into pages\n",
    "metadatas = []\n",
    "texts = []\n",
    "for row in data:\n",
    "  metadatas.append(row.metadata)\n",
    "  texts.append(row.page_content)\n",
    "print(len(metadatas),len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d64bffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the embedding model and cache it in our artifacts directory\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding_model_name = \"BAAI/bge-small-en\"\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/mnt/artifacts/model_cache/'\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en\",\n",
    "                                      model_kwargs=model_kwargs,\n",
    "                                      encode_kwargs=encode_kwargs\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506d23b",
   "metadata": {},
   "source": [
    "## Initialise The Vector Database\n",
    "Now we can create the collection in the Qdrant Vector Database.\n",
    "\n",
    "**Note: This step takes several minutes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92be7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Persist the embeddings to disk in our artifacts directory\n",
    "doc_store = Qdrant.from_texts(texts,\n",
    "                              metadatas=metadatas,\n",
    "                              embedding=embeddings,\n",
    "                              path=\"/mnt/artifacts/local_qdrant/\",\n",
    "                              prefer_grpc=True,\n",
    "                              collection_name=\"mlops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34efd00",
   "metadata": {},
   "source": [
    "## Initialise The Model\n",
    "\n",
    "Now that we have the Vector Store and the Embedding Model we need to get the Foundation Model that we will be using.\n",
    "In this case we are leveraging the open source Llama2 model Llama-2-7b-chat-hf. In contrast to third party services like OpenAI this open source model allows you to download the model into your cloud and run it entirely in your enterprises ecosystem meaning you have tighter controls over security and governance.\n",
    "\n",
    "We will:\n",
    "1. Set up the prompt for this use case\n",
    "2. Configure bitsandbytes for the quantisation we need\n",
    "3. Download, configure and save the Llama2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688f17d",
   "metadata": {},
   "source": [
    "### 1. Set up the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e299563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the prompt template to use for the QA bot\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question enclosed within  3 backticks at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Please provide an answer which is factually correct and based on the information retrieved from the vector store.\n",
    "Please also mention any quotes supporting the answer if any present in the context supplied within two double quotes \"\" .\n",
    "\n",
    "{context}\n",
    "\n",
    "QUESTION:```{question}```\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460c21c",
   "metadata": {},
   "source": [
    "### 2. Configure bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f844bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure bitsandbytes\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b3e6e",
   "metadata": {},
   "source": [
    "### 3. Download and configure the model\n",
    "\n",
    "**Note: This step can take several minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80bb6b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:46<00:00, 23.28s/it]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 746/746 [00:00<00:00, 846kB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 18.9MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 5.10MB/s]\n",
      "Downloading added_tokens.json: 100%|██████████| 21.0/21.0 [00:00<00:00, 24.1kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 435/435 [00:00<00:00, 473kB/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=os.environ['DOMINO_DATASETS_DIR'] + '/' + os.environ['DOMINO_PROJECT_NAME'],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c892a6",
   "metadata": {},
   "source": [
    "## Putting it all together!\n",
    "\n",
    "Now we have our Vector Database with our documents in it and our configured model we can create our RAG QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be1713f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the QA chain\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200)\n",
    "rag_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=rag_llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                       retriever=doc_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "                                       return_source_documents=True\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af742d3e",
   "metadata": {},
   "source": [
    "Now we can test our model!\n",
    "\n",
    "Run the following cell and ask a question based on the documents you have added to the vector store. You may want to play with the max_new_tokens parameter in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca5fc2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide your question here : What about Energy for Landlords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The guide provides information on various energy-related topics that are relevant to landlords, including data that landlords can request from tenants to monitor and improve the environmental performance of their properties. The guide mentions that landlords can request data on the energy use and consumption of their tenants, as well as information on waste generation and management. Additionally, the guide highlights the importance of monitoring and measuring energy use to identify areas for improvement and to meet legal requirements such as the Energy Performance Certificate (EPC) and the Minimum Energy Efficiency Standards (MEES).\n",
      "\n",
      "The guide also provides information on various energy-related technologies and opportunities for landlords, including district heat networks, rooftop solar, EV charging, and corporate power purchase agreements (PPAs). The guide notes that these technologies can provide landlords with opportunities to decarbonise their properties and to reduce their energy costs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "user_question = input(\"Please provide your question here :\")\n",
    "result = qa_chain(user_question)\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a9615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
